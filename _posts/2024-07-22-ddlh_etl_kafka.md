---
title: "Sending Data to Kafka using Pyspark"
date: 2024-09-25
last_modified_at: 2024-09-25T16:20:02-05:00
categories:
  - Blog
tags:
  - Python
  - Data Science
link: https://medium.com/@sharmapushpendra342/sending-data-to-kafka-using-pyspark-a52b7ced8d32
---
> "Kafka is a distributed event-streaming platform designed to handle real-time data feeds with high throughput and low latency."

This article details how to use PySpark to send a transformed two-column dataframe to Kafka for real-time data streaming. It also explains how to set up Kafka using the Confluent platform for seamless integration with a Hadoop cluster, avoiding the complexity of installing Kafka locally.


